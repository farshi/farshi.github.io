<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[FARSHI DESIGNS]]></title>
  <link href="http://www.farshidesigns.com/atom.xml" rel="self"/>
  <link href="http://www.farshidesigns.com/"/>
  <updated>2015-05-15T00:04:48+10:00</updated>
  <id>http://www.farshidesigns.com/</id>
  <author>
    <name><![CDATA[Reza Farshi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Setup a AWS ECS Container Purely Using CLI]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/05/14/setup-a-aws-ecs-container-purely-using-cli/"/>
    <updated>2015-05-14T23:03:10+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/05/14/setup-a-aws-ecs-container-purely-using-cli</id>
    <content type="html"><![CDATA[<p>In This Blog post I’m trying to setup an ECS container in a custom cluster with one docker instance inside by using AWS CLI. The AWS user guides partially describes how to setup an EC2 Container service using the AWS CLI but in some steps It leaves some tricks to the reader, for example user have to login to AWS console to setup EC2 machine needed to act as an ECS machine or in one of the steps you have to login and create needed an IAM role and required policies to assign to the EC2 machine. We need to assign appropriate role to the Ec2 Machine to letting it to communicate with ECS service to register and deregister the Ec2 Machine as a resource.</p>

<p>In this post I walk through you to setup everything purely by AWS CLI commands from start to finish. It includes:</p>

<ul>
<li>Configuring AWS CLI environment on the user machine.</li>
<li>Creating key pair which is need to connect to the EC2 machine.</li>
<li>Creating the instance of EC2 machine.</li>
<li>Creating the required IAM role and in-line attached policies to assign to the EC2.</li>
<li>Configuring EC2 machine to be assigned to custom cluster instead of default one.</li>
</ul>


<p>This guide includes other steps which already have been described by AWS user guide itself and I did not add new stuffs to those steps but I reproduce that commands too. These steps are  Including task definition and ruining the task.</p>

<p>Let’s get started with configuring the AWS CLI environment on your machine.</p>

<h2>Step 1 - configure keys</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws configure
</span><span class='line'>AWS Access Key ID []:****************6HEQ
</span><span class='line'>AWS Secret Access Key []:****************mFbV
</span><span class='line'>Default region name []: ap-southeast-2
</span><span class='line'>Default output format []:Json</span></code></pre></td></tr></table></div></figure>


<p>I choose ap-southeast-2 , coz I am using Sydney region.</p>

<h2>Step 2: Create a Cluster</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ecs create-cluster --cluster-name MyCluster
</span><span class='line'>{
</span><span class='line'>    "cluster": {
</span><span class='line'>        "status": "ACTIVE",
</span><span class='line'>        "clusterName": "MyCluster",
</span><span class='line'>        "registeredContainerInstancesCount": 0,
</span><span class='line'>        "pendingTasksCount": 0,
</span><span class='line'>        "runningTasksCount": 0,
</span><span class='line'>        "clusterArn": "arn:aws:ecs:ap-southeast-2:338764315603:cluster/MyCluster"
</span><span class='line'>    }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>This Step is optional, If you don&rsquo;t create a cluster containers will be created on the default cluster.</p>

<h2>Step 3: Launch an Instance with the Amazon ECS AMI</h2>

<p>This step includes some sub steps.</p>

<h3>Step 3-1 : Creating a Key Pair</h3>

<p>To create a key pair named MyKeyPair, use the create-key-pair command, and use the <code>--query</code> option and the <code>--output</code> text option to pipe your private key directly into a file.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ec2 create-key-pair --key-name MyKeyPair --query 'KeyMaterial' --output text &gt; MyKeyPair.pem
</span></code></pre></td></tr></table></div></figure>


<p>If you&rsquo;re using an SSH client on a Linux computer to connect to your instance, use the following command to set the permissions of your private key file so that only you can read it.</p>

<p><code> ~/ chmod 400 MyKeyPair.pem</code></p>

<p>To displaying Your Key Pair to verify you have done the key pair creation.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ec2 describe-key-pairs --key-name MyKeyPair
</span><span class='line'>{
</span><span class='line'>    "KeyPairs": [
</span><span class='line'>        {
</span><span class='line'>            "KeyName": "MyKeyPair",
</span><span class='line'>            "KeyFingerprint": "df:6a:55:cc:66:4f:2e:a3:8b:ca:67:16:be:b9:f5:4a:db:5a:26:1a"
</span><span class='line'>        }
</span><span class='line'>    ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h3>Step 3-2 : Creating a Security Group</h3>

<p>Containers associated with your tasks can map their network ports to ports on the host Amazon ECS container instance so they are reachable from the Internet. If your container has external connectivity, then your container instance security group must allow inbound access to the ports you want to expose.</p>

<p>Here we don’t want to have a docker instance to communicate with outside but I open the port 22 coz later we might want to login into the machine and inspect AWS ecs-agent and our created docker instance. AWS ecs-agent is a docket instance by itself. In the real production environment it’s not a good practice to open ssh port on the ECS machine but if you wan to do it you should choose restricted CIDR instead of 0.0.0.0/0.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ec2 create-security-group --group-name MySecurityGroup --description "My security group”
</span><span class='line'> ~/ aws ec2 authorize-security-group-ingress --group-name MySecurityGroup --protocol tcp --port 22 --cidr 0.0.0.0/0
</span><span class='line'> ~/  aws ec2 describe-security-groups --group-names MySecurityGroup</span></code></pre></td></tr></table></div></figure>


<h3>Step 3-3: Creating userdata.txt to specify ClusterName</h3>

<p>By default, your container instance launches into your default cluster. If you want to launch into your own cluster instead of the default, replacing &lsquo;your_cluster_name&rsquo; with the name of your cluster.</p>

<p><code>#!/bin/bash
echo ECS_CLUSTER=your_cluster_name &gt;&gt; /etc/ecs/ecs.config</code></p>

<p>Create a file <code>userdata.txt</code> and paste these lines into it:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#!/bin/bash 
</span><span class='line'>echo ECS_CLUSTER=MyCluster &gt;&gt; /etc/ecs/ecs.config</span></code></pre></td></tr></table></div></figure>


<h3>Step 3-4 : Creating required instance profile, role and policy</h3>

<p>In this step we want to create the required role with inline policy and assign the role to the instance profile. Because the Amazon ECS container agent makes calls to Amazon ECS on your behalf, you need to launch container instances with an IAM role that authenticates to your account and provides the required resource permissions.</p>

<p>Create a new file <code>ecsPolicy.json</code> using nano or vim and put following lines into the file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "Version": "2012-10-17",
</span><span class='line'>  "Statement": [
</span><span class='line'>    {
</span><span class='line'>      "Sid": "",
</span><span class='line'>      "Effect": "Allow",
</span><span class='line'>      "Principal": {
</span><span class='line'>        "Service": "ec2.amazonaws.com"
</span><span class='line'>      },
</span><span class='line'>      "Action": "sts:AssumeRole"
</span><span class='line'>    }
</span><span class='line'>  ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>Create a new file <code>rolePolicy.json</code> and put the following lines into the file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> {
</span><span class='line'>  "Version": "2012-10-17",
</span><span class='line'>  "Statement": [
</span><span class='line'>    {
</span><span class='line'>      "Effect": "Allow",
</span><span class='line'>      "Action": [
</span><span class='line'>        "ecs:CreateCluster",
</span><span class='line'>        "ecs:DeregisterContainerInstance",
</span><span class='line'>        "ecs:DiscoverPollEndpoint",
</span><span class='line'>        "ecs:Poll",
</span><span class='line'>        "ecs:RegisterContainerInstance",
</span><span class='line'>        "ecs:Submit*"
</span><span class='line'>      ],
</span><span class='line'>      "Resource": [
</span><span class='line'>        "*"
</span><span class='line'>      ]
</span><span class='line'>    }
</span><span class='line'>  ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>And then issue these set of commands:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/.aws/ aws iam create-role --role-name ecsRole --assume-role-policy-document file://ecsPolicy.json
</span><span class='line'>
</span><span class='line'> ~/.aws/ aws iam put-role-policy --role-name ecsRole --policy-name ecsRolePolicy  --policy-document file://rolePolicy.json
</span><span class='line'>
</span><span class='line'> ~/.aws/ aws iam add-role-to-instance-profile --instance-profile-name ecsRole  --role-name ecsRole</span></code></pre></td></tr></table></div></figure>


<h3>Step 3-5 : Running EC2 instance on a default VPC</h3>

<p>The Amazon ECS container agent allows container instances to connect to your cluster. The Amazon ECS container agent is included in the Amazon ECS-optimized AMI, but you can also install it on any EC2 instance that supports the Amazon ECS specification. The Amazon ECS container agent is only supported on EC2 instances.</p>

<p>For finding an AMI which is ECS optimized login into the AWS console then from the console dashboard, choose Launch Instance. On the Choose an Amazon Machine Image (AMI) page, choose Community AMIs. Choose an AMI for your container instance.  you can replace image-id options by  the image-id you find.</p>

<p>I choose this AMI :
<code>amzn-ami-2015.03.b-amazon-ecs-optimized - ami-39017e03</code></p>

<p>So now we can pass security group and IAM instance profile that we created in previous steps.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ec2 run-instances   --image-id ami-39017e03 --count 1 --instance-type t2.micro --key-name MyKeyPair --iam-instance-profile "Name= ecsRole" --security-groups MySecurityGroup --user-data file://userdata.txt</span></code></pre></td></tr></table></div></figure>


<h3>Step 3-6: Adding a Name Tag to Your Instance</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ec2 create-tags --resources i-fcb33a20 --tags Key=Name,Value=MyECSInstance</span></code></pre></td></tr></table></div></figure>


<h2>Step 4:  List Container Instances</h2>

<p>by issuing this command you can see the container instances list. Because we configure ace-agent to be deployed in MyCluster, for listing
the container instance it needs cluster be specified.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ecs list-container-instances --cluster MyCluster
</span><span class='line'>{
</span><span class='line'>    "containerInstanceArns": [
</span><span class='line'>        "arn:aws:ecs:ap-southeast-2:338764315603:container-instance/3de53ed6-5017-46fa-9b9f-37ad8a2b9da6"
</span><span class='line'>    ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>Step 5: Describe your Container Instance</h2>

<p>To list the details of containers in our cluster we can use following commands. The details of containers , amount of CPU , memory capacity and also network ports will be shown.  Container-instances which listed for you by the previous command should be passed to this command.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aaws ecs describe-container-instances --cluster MyCluster --container-instances 3de53ed6-5017-46fa-9b9f-37ad8a2b9da6</span></code></pre></td></tr></table></div></figure>


<h2>Step 6: Register a Task Definition</h2>

<p>For defining the task we need to create a JSON file and specify the amount of memory , number of CPU units, the name of the task , the container image we want to use , and the type of the container.</p>

<p><code>~/ nano sleep360.json</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "containerDefinitions": [
</span><span class='line'>    {
</span><span class='line'>      "name": "sleep",
</span><span class='line'>      "image": "busybox",
</span><span class='line'>      "cpu": 10,
</span><span class='line'>      "command": [
</span><span class='line'>        "sleep",
</span><span class='line'>        "360"
</span><span class='line'>      ],
</span><span class='line'>      "memory": 10,
</span><span class='line'>      "essential": true
</span><span class='line'>    }
</span><span class='line'>  ],
</span><span class='line'>  "family": "sleep360"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>Here our defined task is essential and it means the cluster will be died if this container dies. our task is a simple task which wants to run a bash command  &lsquo;sleep 360&rsquo;  and the container will be terminated after running the command. exactly after 6 minutes. :D</p>

<p>by issuing the following command and passing the created file to the command we be able to register our task definition.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ecs register-task-definition --cli-input-json file://sleep360.json
</span><span class='line'>{
</span><span class='line'>    "taskDefinition": {
</span><span class='line'>        "volumes": [],
</span><span class='line'>        "taskDefinitionArn": "arn:aws:ecs:ap-southeast-2:338764315603:task-definition/sleep360:1",
</span><span class='line'>        "containerDefinitions": [
</span><span class='line'>            {
</span><span class='line'>                "environment": [],
</span><span class='line'>                "name": "sleep",
</span><span class='line'>                "mountPoints": [],
</span><span class='line'>                "image": "busybox",
</span><span class='line'>                "cpu": 10,
</span><span class='line'>                "portMappings": [],
</span><span class='line'>                "command": [
</span><span class='line'>                    "sleep",
</span><span class='line'>                    "360"
</span><span class='line'>                ],
</span><span class='line'>                "memory": 10,
</span><span class='line'>                "essential": true,
</span><span class='line'>                "volumesFrom": []
</span><span class='line'>            }
</span><span class='line'>        ],
</span><span class='line'>        "family": "sleep360",
</span><span class='line'>        "revision": 1
</span><span class='line'>    }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>To be sure that our task is registered, issuing this command will list the defined tasks.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/  aws ecs list-task-definitions
</span><span class='line'>{
</span><span class='line'>    "taskDefinitionArns": [
</span><span class='line'>        "arn:aws:ecs:ap-southeast-2:338764315603:task-definition/sleep360:1"
</span><span class='line'>    ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>Step 7: Run a Task</h2>

<p>To running a task simple use this command. By passing the count argument we can specify how many instance of container spin up on the cluster.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ecs run-task --cluster MyCluster --task-definition sleep360:1 --count 1</span></code></pre></td></tr></table></div></figure>


<p>To listing the task use the following command.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ecs list-tasks --cluster MyCluster
</span><span class='line'>{
</span><span class='line'>    "taskArns": [
</span><span class='line'>        "arn:aws:ecs:ap-southeast-2:338764315603:task/7cceb4d5-8950-42a3-923e-b1859d401399"
</span><span class='line'>    ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>By passing the task ARN (listed above) to the following command we can see details of the running task.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> ~/ aws ecs describe-tasks --cluster MyCluster --task 7cceb4d5-8950-42a3-923e-b1859d401399
</span><span class='line'>{
</span><span class='line'>    "failures": [],
</span><span class='line'>    "tasks": [
</span><span class='line'>        {
</span><span class='line'>            "taskArn": "arn:aws:ecs:ap-southeast-2:338764315603:task/7cceb4d5-8950-42a3-923e-b1859d401399",
</span><span class='line'>            "overrides": {
</span><span class='line'>                "containerOverrides": [
</span><span class='line'>                    {
</span><span class='line'>                        "name": "sleep"
</span><span class='line'>                    }
</span><span class='line'>                ]
</span><span class='line'>            },
</span><span class='line'>            "lastStatus": "RUNNING",
</span><span class='line'>            "containerInstanceArn": "arn:aws:ecs:ap-southeast-2:338764315603:container-instance/3de53ed6-5017-46fa-9b9f-37ad8a2b9da6",
</span><span class='line'>            "clusterArn": "arn:aws:ecs:ap-southeast-2:338764315603:cluster/MyCluster",
</span><span class='line'>            "desiredStatus": "RUNNING",
</span><span class='line'>            "taskDefinitionArn": "arn:aws:ecs:ap-southeast-2:338764315603:task-definition/sleep360:1",
</span><span class='line'>            "containers": [
</span><span class='line'>                {
</span><span class='line'>                    "containerArn": "arn:aws:ecs:ap-southeast-2:338764315603:container/d440587d-b23b-45f3-a2a8-ff8b195d0240",
</span><span class='line'>                    "taskArn": "arn:aws:ecs:ap-southeast-2:338764315603:task/7cceb4d5-8950-42a3-923e-b1859d401399",
</span><span class='line'>                    "name": "sleep",
</span><span class='line'>                    "networkBindings": [],
</span><span class='line'>                    "lastStatus": "RUNNING",
</span><span class='line'>                    "exitCode": 0
</span><span class='line'>                }
</span><span class='line'>            ]
</span><span class='line'>        }
</span><span class='line'>    ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>Step 8 (Final): SSH into the EC2 machine an list the  container</h2>

<p>In the final step  we want to ssh into the machine and list the containers inside the machine.</p>

<p>ssh -i MyKeyPair.pem ec2-user@EC2-Public-IP-ADDRESS</p>

<p>after login into the machine, you can issue  <code>packer -ps</code>  command to list the containers. you should see the  <code>ecs-agent</code> and  <code>sleep 360</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[ec2-user@ip-xxx-xxx-xxx-xx ~]$ docker ps
</span><span class='line'>CONTAINER ID        IMAGE                            COMMAND             CREATED             STATUS                  PORTS                        NAMES
</span><span class='line'>95d32fb0a1a2        busybox:latest                   "sleep 360"         1 seconds ago       Up Less than a second                                ecs-sleep360-1-sleep-fec1a8f1fbfd9d82d601
</span><span class='line'>0ad94851d185        amazon/amazon-ecs-agent:latest   "/agent"            11 minutes ago      Up 11 minutes           127.0.0.1:51678-&gt;51678/tcp   ecs-agent
</span></code></pre></td></tr></table></div></figure>


<p>Hope you enjoy this blog post and helps you to understand the ECS service more.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Amazon S3 Notes]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/27/amazon-s3-notes/"/>
    <updated>2015-04-27T22:48:19+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/27/amazon-s3-notes</id>
    <content type="html"><![CDATA[<p>Some Notes about the Amazon Simple Storage Service (S3) service. You will find it useful if you want to prepare for AWS architecture certificate exam.</p>

<p>Amazon Simple Storage Service (S3) :</p>

<ul>
<li>Files can be from 1 Byte to 5 TB</li>
<li>Files are stored in Buckets and there is no limit.</li>
<li>Buckets name must be unique in a region level</li>
<li>Buckets are private by default</li>
<li>S3 Files are stored as a object in buckets</li>
<li>S3 supports MultiPart uploads,It is necessary for files bigger than 5Gb</li>
<li>S3 support resumable uploads.</li>
<li>S3 is consistent cross availability zones</li>
<li>S3 has a Life Cycle management, you can archive data after a specific time period from upload time in glacier.</li>
<li>Amazon S3 designed for 11 nines durability , 99.99999999999 in a given year</li>
<li>Amazon S3 availability is 99.99% in a given  year</li>
<li>Files can be encrypted on S3</li>
<li>S3 has versioning feature , includes all writes even if you delete an object</li>
<li>When you enable the versioning , you can not disable it , but you can suspend it</li>
<li>Reduced Redundancy Storage (RSS) data availability and durability is 99.99%</li>
<li>RSS is suitable for storing low frequency data.</li>
<li>RSS Cost: 3 Cent per GB per Month</li>
<li>Glacier is a low cost storage service suitable for data archiving.</li>
<li>Glacier Cost: 1 Cent per GB per Month</li>
<li>Glacier retrieval time 3 to 5 Hours</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Amazon SNS Notes]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/27/amazon-sns-notes/"/>
    <updated>2015-04-27T22:10:57+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/27/amazon-sns-notes</id>
    <content type="html"><![CDATA[<p>Some Notes about the Amazon SMS service. You will find it useful if you want to prepare for AWS architecture certificate exam.</p>

<p>Amazon Simple Notification service  (SNS) :</p>

<ul>
<li>Is a web service that makes it easy to set up, operate, and send notifications from the cloud.</li>
<li>Amazon SNS allows the &ldquo;publish-subscribe&rdquo; (pub-sub) messaging paradigm.</li>
<li>SNS eliminates the need to periodically check or pull for new information and updates.</li>
<li>it is inexpensive, pay-as-you-go model with no up-front costs.</li>
<li>Amazon SNS can be deliver notifications by SMS text messages or email, to Amazon Simple Queue Service (SQS) queues, or any HTTP endpoint.</li>
<li>To prevent messages from being lost,all messages published to Amazon SNS are stored redundantly across multiple availability zones.</li>
<li>SNS Topic allows you to group multiple recipients. It acts like a access point for allowing recipients to dynamically subscribe for identical copies of the same notification.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Amazon SWF Notes]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/27/amazon-swf-notes/"/>
    <updated>2015-04-27T22:10:17+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/27/amazon-swf-notes</id>
    <content type="html"><![CDATA[<p>Some Notes about the Amazon SWF service. You will find it useful if you want to prepare for AWS architecture certificate exam.</p>

<p>Amazon Simple Work flow Service (SWF):</p>

<ul>
<li>is a web service that makes it easy to coordinate work across distributed application components.</li>
<li>enables applications for a range of use cases, including media processing, web application back-ends, business process work flows, and analytics pipelines.</li>
<li>Tasks represent invocations of various processing steps in an application which can be performed by executable code, web service calls, human actions and scrips.</li>
<li>SWF presents a task-oriented API</li>
<li>SWF ensures that a task is assigned only once and is never duplicated.</li>
<li>SWF keeps track of all the tasks and events in an application.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Amazon SQS Notes]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/27/amazon-sqs/"/>
    <updated>2015-04-27T22:09:04+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/27/amazon-sqs</id>
    <content type="html"><![CDATA[<p>Some Notes about the Amazon SQS service. You will find it useful if you want to prepare for AWS architecture certificate exam.</p>

<p>Amazon Simple queue service (SQS):</p>

<ul>
<li>is A web service that gives you access to a message queues.</li>
<li>Queues can be used to store messages while waiting for a computer to process them.</li>
<li>is distributed Queue System.</li>
<li>is fast and reliable</li>
<li>A queue is a temporary repository for messages hat are waiting processing.
*By using SQS you can decouple the components of an application so they run independently.</li>
<li>Messages can contain up to 256KB of text in any format.</li>
<li>Messages can be retrieved by any distributed component by using Amazon SQS API.</li>
<li>Amazon SQS ensures delivery of each message at least once. so one message can be read by many distributed application components simultaneously. And They are remained until you remove them from the queue yourself.</li>
<li>SQS does not support FIFO ( First In Firs Out).</li>
<li>SQS is a pull system , and messages are not pushed out like SNS.</li>
<li>Visibility time out period for a message starts when a component retrieves the message. The default visibility time out is minimum 30 seconds and maximum 12 hours.</li>
<li>SQS Billed at 64kb Chunks.</li>
<li>Firs 1 million Amazon SQS request per month are free.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Amazon VPC Notes]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/27/amazon-vpc/"/>
    <updated>2015-04-27T22:08:11+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/27/amazon-vpc</id>
    <content type="html"><![CDATA[<p>Some Notes about the Amazon VPC service. You will find it useful if you want to prepare for AWS architecture certificate exam.</p>

<p>Amazon VPC:</p>

<ul>
<li>It is like a virtual data center in cloud.</li>
<li>lets you provision a logically isolated sections of the Amazon web service (AWS) cloud.</li>
<li>you have complete control over your virtual network environment.</li>
<li>you can select your own IP address range.</li>
<li>you can create your subnets.</li>
<li>you can configure route tables.</li>
<li>you can setup network gateways ( Internet gateway and Customer gateway).</li>
<li>With VPC you have two level of security:

<ul>
<li>  instance security groups.</li>
<li>  subnet network access control lists (ACLS)</li>
</ul>
</li>
<li>Using Amazon Direct Connect you can connect your corporate data center and your AWS VPC.</li>
<li>There is a default VPC which is user friendly, allowing you to immediately deploy instances.</li>
<li>All Subnets in default VPC have an Internet gateway attached.</li>
<li>Each EC2 instance has both a public and private IP addresses.</li>
<li>If you delete the default VPC the only way to get it back is to contact AWS.</li>
<li>you can user VPC Peering to connect one VPC with another.</li>
<li>when you use VPC Peering , instances behave as if they were on the same private network.</li>
<li>you can peer even VPC&rsquo;s with other AWS accounts.</li>
<li>Peering is in a star configuration.So Siblings VPC&rsquo;s can not directly talk to each other and should use centric one.</li>
<li>Elastic IP addresses, Internet Gateways, VPCs per region : Max 5</li>
<li>VPC connections per region, Customer Gateways per region: Max 50</li>
<li>Route tables per region: Max 200</li>
<li>Security groups per VPC: Max 100</li>
<li>Rules per security group: Max 50</li>
<li>Dedicated VPC&rsquo;s are expensive because all of instance underneath will be dedicated.</li>
<li>When you create a VPC, one route table and one ACL will be created automatically.</li>
<li>Your subnets can not be in different availability zones , just in one AZ.</li>
<li>you can have only One Internet gateway per VPC.</li>
<li>putting an instance in a public subnet is not enough to make public access to that instance.you should assign public IP address to it to make it accessible from the Internet.</li>
<li>For making a NAT instance as a router for routing private subnet traffic to the Internet you should disable source/destination check for that NAT instance.</li>
<li>Access Control list act as firewall and rules are applied to the entire subnet.
*If you don&rsquo;t associate a ACL to a subnet, default ACL which allows all incoming and outgoing traffic will be assigned to a subnet automatically.</li>
<li>Rules in ACL assigned order numbers, so rule #100 evaluated before rule #200. Amazon recommends to increment rules number by 100.</li>
<li>When you create a new ACL, incoming and outgoing traffic is denied by default.</li>
<li>Like as a firewall , Only one ACL can be assigned to the subnet.cardinality between ACL-Subnet is Many to one.</li>
<li>Amazon corporate network is segregated from AWS network.</li>
<li>Port scanning is not allowed in AWS by default. for vulnerability scan you must request it from amazon for a short period.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Amazon RedShift Notes]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/27/amazon-redshift-notes/"/>
    <updated>2015-04-27T22:06:33+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/27/amazon-redshift-notes</id>
    <content type="html"><![CDATA[<p>Some Notes about the Amazon RedShift service. You will find it useful if you want to prepare for AWS architecture certificate exam.</p>

<p>Amazon RedShift is the Amazon warehouse service in cloud, characteristics are :</p>

<ul>
<li>fast and powerful</li>
<li>fully managed service</li>
<li>Peta byte scale</li>
<li>Instead of storing data as a series of rows, it has columnar data storage</li>
<li>Column-based storage require far fewer I/Os so greatly improving query performance</li>
<li>10 Time Faster than traditional data warehouses.</li>
<li>in column-base storage , similar data is stored sequentially , so data can be compressed much more than row-base storage,</li>
<li>RedShift automatically samples your data and select the most appropriate compression schema.</li>
<li>Redshift has MPP ( Massively Parallel Processing) feature.</li>
<li>by MPP , data are distributed and queries load across all nodes to your data</li>
<li>cost is less than a tenth of most other data warehouse solutions.</li>
<li>configuration of RedShif can be Single node(160Gb) or Multi-node.</li>
<li>in Multi-Node mode , One node is Leader node , and then you can create  up to 128 compute nodes.</li>
<li>Leader node manages client connections and receives queries</li>
<li>Computed Node store data and perform queries and do computations</li>
<li>You will not charged for leader node hours; only compute nodes will incur charges.</li>
<li>Encrypted in transit using SSL.</li>
<li>Encrypted at rest using AES-256</li>
<li>By default Redshift takes care of key management</li>
<li>You can manage your own keys through HSM or by Amazon Key Management Service.</li>
<li>Currently only available in 1 AZ</li>
<li>Can restore snapshots to new AZ&rsquo;s in the event of outage.</li>
<li>Fail over is not automatically , it&rsquo;s manual.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Amazon DynamoDB Notes]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/27/amazon-dynamodb-notes/"/>
    <updated>2015-04-27T22:05:47+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/27/amazon-dynamodb-notes</id>
    <content type="html"><![CDATA[<p>Some Notes about the Amazon DynamoDB service. You will find it useful if you want to prepare for AWS architecture certificate exam.</p>

<ul>
<li>Amazon DynamoDb is a fast and flexible NoSQL database service.</li>
<li>single digit millisecond latency at any scale</li>
<li>fully managed</li>
<li>supports both document and key-value data</li>
<li>It&rsquo;s flexible data model and reliable performance make it a great fit for mobile, web, gaming, ad-tech, IoT, and many other applications.</li>
<li>Stored on SSD storage</li>
<li>spread across 3 geographically distinct data centres</li>
<li>It supports both of Eventual Consistency and Strong Consistency.</li>
<li>Integrated with RedShift and Elastic Map Reduce (EMR)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Amazon RDS Notes]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/27/amazon-rds-notes/"/>
    <updated>2015-04-27T22:04:28+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/27/amazon-rds-notes</id>
    <content type="html"><![CDATA[<p> Some Notes about the Amazon RDS service. You will find it useful if you want to prepare for AWS architecture certificate exam.</p>

<ul>
<li>Amazon RDS now supports these Relational (OLTP): MySQL, Oracle , SQL , PostgreSql, Aurora</li>
<li>Supports Non-Relational No-SQL database , DynamoDB</li>
<li>Supports Data warehousing database (OLAP), RedShift</li>
<li>Supports ElasticCache (fast in-memory cache service), MemCached and Redis</li>
<li>Aurora is a MySql Compatible Database , Not accessible yet.</li>
<li>Aurora provides up to five times better performance than MySQL.</li>
<li>Aurora cost is one tenth that of a commercial database while delivering similar performance and availability.</li>
<li>Aurora start with 10Gb, Scales in 10 Gb increments to 64Tb.</li>
<li>compute resources can scale up to 32vCPUs and 244 Gb of Memory.</li>
<li>Aurora storage is self-healing. Data blocks scanned and fixed automatically.</li>
<li>you can loose 2 copies without effecting write performance.</li>
<li>you can loose 3 copies without effecting read performance.</li>
<li>Maximum Backup Retention Period for RDS is 35 days</li>
<li>When you want restore database to specific time , entirely new database will be created and endpoints will be different from the original database endpoint</li>
<li>you can bring your own license in the case of selecting Oracle and SQL Server as a RDS Engine.</li>
<li>You can modify MySql DB instance and increase storage size , change engine , change database name , password and &hellip;</li>
<li>Microsoft SQL server DB instance has some restrictions:</li>
<li> You can not modify Microsoft SQL server DB instance storage size , Amazon does not support increasing storage on a SQL server DB Instance.</li>
<li> A newly created SQL server does not contain database. you should connect from SQL server management studio and create your database.</li>
<li>The maximum storage size for SQL server DB instance is 1024 GB.</li>
<li>Read replicas are available in Amazon RDS for MySQL, PostgreSQL, and Amazon Aurora.</li>
<li>Amazon RDS for MySQL and PostgreSQL allow you to add up to 5 read replicas to each DB Instance.</li>
<li>With Aurora you will get 6 copies of your data (2 copies in each 3 AZ).</li>
<li>Replication is only supported for the InnoDB storage engine.</li>
<li>When you provision a Multi-AZ DB Instance, Amazon RDS automatically creates a primary DB Instance and synchronously replicates the data to a standby instance in a different Availability Zone (AZ)</li>
<li>you can monitor you Read Replica using CloudWatch Replica Lag statistic. If a replica lags too far behind for your environment, consider deleting and recreating the Read Replica</li>
<li>If you scale the source DB instance, you should also scale the Read Replicas.
<em>you can create ReadReplica1 from MyDBInstance, and then create ReadReplica2 from ReadReplica1.
</em>Before a DB instance can serve as a source DB instance, you must enable automatic backups on the source DB instance by setting the backup retention period to a value other than 0.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[EC2 Notes]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/25/ec2-essentials/"/>
    <updated>2015-04-25T12:27:57+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/25/ec2-essentials</id>
    <content type="html"><![CDATA[<p>Some Notes about the Elastic compute cloud , you will find it useful if you want to prepare for AWS architecture certificate exam.</p>

<ul>
<li>Elastic Compute Cloud provides re-sizable compute capacity in cloud.</li>
<li>It can be scale up or down as computing requirements changed.</li>
<li>EC2 Options: Free Tier, On Demand , Reserved and Spot.</li>
<li>Data Stored on a local instance storage will be deleted when you stop the instance.</li>
<li>EBS backed storage will persist independently of the life of the instance</li>
<li>AWS uses standard technologies detailed in DoD 5220.22-M or NIST 800-88 guidelines for media sanitization to destroy data as part of the decommissioning process.</li>
<li>EBS volume can be attached to only One instance at a time.</li>
<li>Types of storage backed by EBS:

<ul>
<li>  General purpose SSD , 99.999% availability,</li>
<li>  Provisioned IOPS SSD, Designed for IO intensive applications</li>
<li>  Magnetic, Low cost , Suitable for infrequent accessed data</li>
</ul>
</li>
<li>Identity Access Management (IAM) roles can not be assigned to an EC2 instance after the instance has been created.</li>
<li>You can not add or change roles to an existing EC2 instance but you can change the permissions of a assigned role.</li>
<li>EC2 placement group properties:

<ul>
<li>  group of logical groups of instances in only one singe AZ</li>
<li>  Are low latency ; has 10GBbps network throughput.</li>
<li>  The name you choose for placement group should be unique in AWS account</li>
<li>  Same size instances recommended to be put in a group</li>
<li>  placement groups cannot be merged.</li>
<li>  you can add existing instances to your placement group by creating AMI form that instance and then launch it to your placement group</li>
</ul>
</li>
<li>Lambda is a compute service which run a code in response of events occurs in your resources and automatically manage that resource for you.</li>
<li>Responses of lambda including capacity provisioning, OS and servers maintenance, security patch , logging and &hellip;</li>
<li>Supported programming language for lambda is JavaScript.</li>
<li>Lambda designed to be available in 99.99%</li>
<li>First one million request of Lambda are free and there after is 0.20 per 1 mil request</li>
<li>Copying snapshots that were encrypted with non-default AWS Key Management Service master keys is not supported at this time.</li>
<li>Snapshots are sent/stored on Amazon S3</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Amazon AWS Numerical Facts]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/24/amazon-aws-numbers-and-default-limits-facts/"/>
    <updated>2015-04-24T16:01:40+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/24/amazon-aws-numbers-and-default-limits-facts</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve collected some information about default limits in AWS and other numerical facts from <a href="http://aws.amazon.com/">Amazon AWS official website</a>. May be you find it useful if you want to prepare for AWS architecture certification exam. This post my be updated in the future.</p>

<ul>
<li>AWS is available in : 190 countries</li>
<li>Number of available regions: 11</li>
<li>Number of Edge Locations: 52</li>
<li>Availability zones per regions: two or more</li>
<li>Amazon S3 designed for 11 nines durability , 99.99999999999% in a given year</li>
<li>Amazon S3 availability is 99.99% in a given year</li>
<li>Objects size range in S3  is :  Min: 1 Byte , Max: 5TB</li>
<li>S3 Number of buckets: 100</li>
<li>Number of objects you can store: UNLIMITED</li>
<li>Glacier retrieve time : 3 to 5 Hours</li>
<li>RSS type durability is %99.99 instead Standard S3 which is %99.99999999999</li>
<li>RDS size range : Min: 5GB , Max:3TB</li>
<li>Aurora size range : Min: 10GB  Max: 64TB</li>
<li>Aurora Availability : 2 Copies for each 3 Zone &ndash;> 6 Copies</li>
<li>Elastic Block Storage (EBS) size , Min: 1GB  , Max: 1TB</li>
<li>VPC per region Max : 5 (default - increased upon request)</li>
<li>Internet Gateway per region : Max 5 (default - increased upon request)</li>
<li>Customer Gateways per region : Max 50 (default - increased upon request)</li>
<li>Elastic IP addresses per region: Max 5 (default - increased upon request)</li>
<li>Rout tables per VPC : Max 200 (default - increased upon request)</li>
<li>Internet Attached to a subnet at time : Only 1</li>
<li>Security group per VPC : Max 100</li>
<li>Rules per Security Group: Max 50</li>
<li>VPN connections per region: Max 50</li>
<li>General purpose SSD EBS availability: 99.999%</li>
<li>General purpose SSD EBS IOPS per GB: 3 to 3000 ( just for short period)</li>
<li>Simple Queue Service(SQS) Message Size : Max 256 Kb</li>
<li>AWS CloudFormaton Limits : 20 stack</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sublime Text as a Default Editor for Git and Others]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/16/sublime-text-as-a-default-editor-for-git-and-others/"/>
    <updated>2015-04-16T13:37:09+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/16/sublime-text-as-a-default-editor-for-git-and-others</id>
    <content type="html"><![CDATA[<p>If you want to set sublime as the main editor for git and other programs on your mac, depends on what you bash you use you should edit  ~/.bash_profile or ~/.bashrc or ~/.zshrc and put these lines on it:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export VISUAL='subl -w'
</span><span class='line'>export EDITOR="$VISUAL"
</span><span class='line'>export GIT_EDITOR="$VISUAL"
</span></code></pre></td></tr></table></div></figure>


<p>Then open a new terminal and run this command :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ln -s "/Applications/Sublime Text 2.app/Contents/SharedSupport/bin/subl" ~/bin/subl</span></code></pre></td></tr></table></div></figure>


<p> Now sublime can be run as a console program and when you hit <code>git commit</code> command sublime shows up in a new Tab. Refer to <a href="https://www.sublimetext.com/docs/2/osx_command_line.html">Sublime documentation</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installation Tips - Octopress Over GitHubPages.]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/15/an-installation-tips-octopress-over-githubpages/"/>
    <updated>2015-04-15T13:43:48+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/15/an-installation-tips-octopress-over-githubpages</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve recently setup my weblog  using Octopress weblog framework over githubpages. I noticed some delicate hints should be applied when setting up Octopress over GitHubPages. When you are trying to install the Octopress weblog framework over your GitHubPages, according to the Octopress installation guide you should fist login into your GitHub account and create a repository and  name the repository with the format username.github.io, where username is your GitHub user name or organization name. now some tips to prevent getting errors like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>c## Pushing generated _deploy website
</span><span class='line'>To git@github.com:farshi/farshi.github.io.git
</span><span class='line'> ! [rejected]        master -&gt; master (non-fast-forward)
</span><span class='line'>error: failed to push some refs to 'git@github.com:farshi/farshi.github.io.git'
</span><span class='line'>To prevent you from losing history, non-fast-forward updates were rejected
</span><span class='line'>Merge the remote changes (e.g. 'git pull') before pushing again.  See the
</span><span class='line'>'Note about fast-forwards' section of 'git push --help' for details.</span></code></pre></td></tr></table></div></figure>


<p>Tip 1: In the page of creating the repository  you should not select &lsquo;Initialize this repository with a README&rsquo;. Unless when you hit rake deploy command you will get this error.</p>

<p>Tip 2: After creating repository you should specify your repository to octopress by hitting this command &lsquo;rake setup&hellip; &rsquo; , when you asked to enter the URI for your repository , stick to the https URL instead of git@ URI.</p>

<p>I hope it helps you to have a smooth Octopress setup.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Finally I Decided to Blog]]></title>
    <link href="http://www.farshidesigns.com/blog/2015/04/14/finally-i-decided-to-blog/"/>
    <updated>2015-04-14T01:45:43+10:00</updated>
    <id>http://www.farshidesigns.com/blog/2015/04/14/finally-i-decided-to-blog</id>
    <content type="html"><![CDATA[<p>Every time I was reading some professional hackers blogs, I thought to myself how good it would be if I had my own weblog and  streamed my thoughts through it.</p>

<p>Today I&rsquo;m so happy and proud of myself coz finally I decided to create my own weblog. I believe in this:</p>

<blockquote><p>Do the difficult things while they are easy and do the great things while they are small. A journey of a thousand miles must begin with a single step.</p><footer><strong>Lao Tzu</strong></footer></blockquote>


<p></p>
]]></content>
  </entry>
  
</feed>
